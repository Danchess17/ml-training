{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZYliUx4o70F"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NclAZKZo70J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0L4eY5Mo70L"
      },
      "outputs": [],
      "source": [
        "image_dir = 'Pascal-part/JPEGImages'\n",
        "mask_dir = 'Pascal-part/gt_masks'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5hrPORfo70M"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "laukO0cZo70N"
      },
      "outputs": [],
      "source": [
        "def dataset_freq(image_dir, mode='train'):\n",
        "    dataset = 'Pascal-part/' + mode + '_id.txt'\n",
        "    size_count = {}\n",
        "    with open(dataset, 'r') as file:\n",
        "        for filename in file.readlines():\n",
        "            image_path = os.path.join(image_dir, filename.strip() + '.jpg')\n",
        "            with Image.open(image_path) as img:\n",
        "                size = img.size\n",
        "                if size in size_count:\n",
        "                    size_count[size] += 1\n",
        "                else:\n",
        "                    size_count[size] = 1\n",
        "    # Sort the dictionary by count in decreasing order\n",
        "    sorted_size_count = dict(sorted(size_count.items(), key=lambda item: item[1], reverse=True))\n",
        "    return sorted_size_count\n",
        "\n",
        "dataset_freq(image_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTATU08Xo70Q"
      },
      "source": [
        "We need images of the same size to begin training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPyZ-UuDo70R",
        "outputId": "4cfaef4d-bbc2-4eb7-953a-69938ef1bf5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 500)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def dataset_max_image_size(image_dir, mode='train'):\n",
        "    max_height, max_width = 0, 0\n",
        "    dataset = 'Pascal-part/' + mode + '_id.txt'\n",
        "    with open(dataset, 'r') as file:\n",
        "        for filename in file.readlines():\n",
        "            image_path = os.path.join(image_dir, filename.strip() + '.jpg')\n",
        "            with Image.open(image_path) as image:\n",
        "                max_height, max_width = max(max_height, image.height), max(max_width, image.width)\n",
        "    return max_height, max_width\n",
        "\n",
        "dataset_max_image_size(image_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zkvIOtYo70S"
      },
      "source": [
        "I will do padding to (500, 500, 3) for all images and padding to (500, 500) for all masks. It's a function for making np.array square-shaped:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQtxKEXOo70S"
      },
      "outputs": [],
      "source": [
        "def padding(arr, target_size=(500, 500, 3)):\n",
        "    pad_width_rows = (target_size[0] - arr.shape[0])\n",
        "    pad_width_cols = (target_size[1] - arr.shape[1])\n",
        "    pad_width = [\n",
        "        (pad_width_rows // 2, pad_width_rows - (pad_width_rows // 2)),\n",
        "        (pad_width_cols // 2, pad_width_cols - (pad_width_cols // 2)),\n",
        "    ]\n",
        "    if len(target_size) == 3:\n",
        "        pad_width += [(0, 0)]\n",
        "    return np.pad(arr, pad_width, 'constant')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puQyDOZ7o70T"
      },
      "source": [
        "Now we can do padding for each jpg file and each corresponding mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzC7yp9io70T"
      },
      "outputs": [],
      "source": [
        "def dataset_padding(image_dir, mask_dir, mode='train'):\n",
        "    h, w = dataset_max_image_size(image_dir, mode)\n",
        "    dataset = 'Pascal-part/' + mode + '_id.txt'\n",
        "    X, y = [], []\n",
        "    with open(dataset, 'r') as file:\n",
        "        for filename in file.readlines():\n",
        "            image_path = os.path.join(image_dir, filename.strip() + '.jpg')\n",
        "            mask_path = os.path.join(mask_dir, filename.strip() + '.npy')\n",
        "            with Image.open(image_path) as image:\n",
        "                img = np.array(image)\n",
        "                padded_img = padding(img, (h, w, 3))\n",
        "                X.append(padded_img)\n",
        "                with open(mask_path, 'rb') as filemask:\n",
        "                    mask = np.load(filemask)\n",
        "                    padded_mask = padding(mask, (h, w))\n",
        "                    y.append(padded_mask)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # y = to_categorical(y, num_classes=7)\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiJHAjUdo70U"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = dataset_padding(image_dir, mask_dir, mode='train')\n",
        "X_val, y_val = dataset_padding(image_dir, mask_dir, mode='val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYNeBin_o70U"
      },
      "source": [
        "Now we have images and masks of the same size and can train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8G-396co70V"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgOTNkRo70V"
      },
      "source": [
        "I will choose Keras, but also we can choose Pytorch and Tensorflow for building and training model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LjXMntBo70V"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3_HBwp8po70W"
      },
      "outputs": [],
      "source": [
        "from keras import Input, Model\n",
        "from keras.layers import *\n",
        "from keras import backend as be\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "from keras.metrics import *\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Unet architecture:"
      ],
      "metadata": {
        "id": "5glT9JBkqXUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MyUnet(img_size=(500, 500, 3), num_classes=7):\n",
        "    inputs = Input(shape=img_size)\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\", name=\"entry_conv2d\")(inputs)\n",
        "    x = BatchNormalization(name=\"entry_bn\")(x)\n",
        "    x = Activation(\"relu\", name=\"entry_act\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = Activation(\"relu\", name=str(filters) + \"_act_1\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\", name=str(filters) + \"_sep_1\")(x)\n",
        "        x = BatchNormalization(name=str(filters) + \"_bn_1\")(x)\n",
        "\n",
        "        x = Activation(\"relu\", name=str(filters) + \"_act_2\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\", name=str(filters) + \"_sep_2\")(x)\n",
        "        x = BatchNormalization(name=str(filters) + \"_bn_2\")(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\", name=str(filters) + \"_pool\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(filters, 1, strides=2, padding=\"same\", name=str(filters) + \"_conv2d\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual], name=str(filters) + \"_add\")  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = Activation(\"relu\", name=str(filters) + \"_act_3\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\", name=str(filters) + \"_trans_1\")(x)\n",
        "        x = BatchNormalization(name=str(filters) + \"_bn_3\")(x)\n",
        "\n",
        "        x = Activation(\"relu\", name=str(filters) + \"_act_4\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\", name=str(filters) + \"_trans_2\")(x)\n",
        "        x = BatchNormalization(name=str(filters) + \"_bn_4\")(x)\n",
        "\n",
        "        x = UpSampling2D(2, name=str(filters) + \"_up\")(x)\n",
        "        # Project residual\n",
        "        residual = UpSampling2D(2, name=str(filters) + \"_up_res\")(previous_block_activation)\n",
        "        residual = Conv2D(filters, 1, padding=\"same\", name=str(filters) + \"_conv2d_res\")(residual)\n",
        "        x = add([x, residual], name=str(filters) + \"_add_res\")  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\", name=\"second_conv2d\")(x)\n",
        "    # Define the model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TKzsGATkpyx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training a Model"
      ],
      "metadata": {
        "id": "yAqSK_fmyszD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train our model:"
      ],
      "metadata": {
        "id": "Ke74xZT6rI3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyUnet()\n",
        "# model.summary()\n",
        "be.clear_session()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss=CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[MeanIoU(numclasses=7)])\n",
        "print('compiled')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=7, batch_size=1, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "-jee9u4-qnNJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}